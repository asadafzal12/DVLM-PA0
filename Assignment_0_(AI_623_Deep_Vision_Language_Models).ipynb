{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task-1: Inner Workings of ResNet-152**\n"
      ],
      "metadata": {
        "id": "A7-JZmmyGVQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Baseline Setup"
      ],
      "metadata": {
        "id": "VosdaL4sGtky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "# Load pre-trained ResNet-152\n",
        "model = models.resnet152(pretrained=True)"
      ],
      "metadata": {
        "id": "ytQSb4eW5pYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)  # CIFAR-10 has 10 classes"
      ],
      "metadata": {
        "id": "qFI-eyIc96VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze only the classification head\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "iwKNJGJ4-F1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),   # ResNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
        "val_dataset   = datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Training function\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    correct, total, running_loss = 0, 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    return running_loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Validation function\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total, running_loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    return running_loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Train for 5 epochs\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
        "    val_loss, val_acc = validate(model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irYundwB-NA5",
        "outputId": "99e47236-7f5d-414a-d68a-9dd8a38759e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.6695, Train Acc: 77.97% | Val Loss: 0.5093, Val Acc: 82.75%\n",
            "Epoch 2/5 | Train Loss: 0.5155, Train Acc: 82.19% | Val Loss: 0.5283, Val Acc: 81.92%\n",
            "Epoch 3/5 | Train Loss: 0.4880, Train Acc: 83.20% | Val Loss: 0.4687, Val Acc: 83.98%\n",
            "Epoch 4/5 | Train Loss: 0.4722, Train Acc: 83.56% | Val Loss: 0.4600, Val Acc: 84.43%\n",
            "Epoch 5/5 | Train Loss: 0.4606, Train Acc: 84.17% | Val Loss: 0.4698, Val Acc: 84.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sd_Q5K7ilSc",
        "outputId": "76672f45-d7e9-441d-9bb2-3cb81b3af3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# TASK-1\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Residual Connections in Practice"
      ],
      "metadata": {
        "id": "D0s_rs9LIT5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Disable Skip Connection"
      ],
      "metadata": {
        "id": "rF-la3tpJ4uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Load pre-trained ResNet-152\n",
        "model = models.resnet152(pretrained=True)\n",
        "\n",
        "# Freeze backbone except classification head\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace final classification layer for CIFAR-10\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "# -------- Disable skip connections in a few blocks --------\n",
        "# We will modify some Bottleneck blocks to remove the skip connection\n",
        "\n",
        "# Access the first layer group (layer1)\n",
        "for i, block in enumerate(model.layer1):\n",
        "    if i < 2:  # modify first two residual blocks\n",
        "        # Save original forward\n",
        "        original_forward = block.forward\n",
        "\n",
        "        # Redefine forward without skip connection\n",
        "        def forward_no_skip(x):\n",
        "            out = block.conv1(x)\n",
        "            out = block.bn1(out)\n",
        "            out = block.relu(out)\n",
        "            out = block.conv2(out)\n",
        "            out = block.bn2(out)\n",
        "            out = block.relu(out)\n",
        "            out = block.conv3(out)\n",
        "            out = block.bn3(out)\n",
        "            # Skip connection removed\n",
        "            return block.relu(out)\n",
        "\n",
        "        block.forward = forward_no_skip"
      ],
      "metadata": {
        "id": "O5EKw--tIbBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # This ensures all layers are on GPU"
      ],
      "metadata": {
        "id": "HZkMI8vkK16U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "PHl3vP_nfNTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    correct, total, running_loss = 0, 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100 * correct / total"
      ],
      "metadata": {
        "id": "Yj62Rg7efZFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total, running_loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100 * correct / total"
      ],
      "metadata": {
        "id": "Wr9tZjsUfiN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_one_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NeDLU1ifs1Y",
        "outputId": "562724fd-0dfd-4c73-a73c-816aae857ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function train_one_epoch at 0x7fbdb003e2a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
        "    val_loss, val_acc = validate(model, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "RNqBnJz5flRu",
        "outputId": "ad9296a0-ed21-4fd7-acb0-9c996b1f4f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2034210112.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 5 epochs\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
        "    val_loss, val_acc = validate(model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "GXnk9OVOKCCQ",
        "outputId": "8e993403-6c19-4dea-a1a7-785bf3ecf617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_one_epoch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2727071681.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_one_epoch' is not defined"
          ]
        }
      ]
    }
  ]
}